to run test:
python manage.py test cooking.tests.test_performance -v 2

performance review 
Token Reduction:
15 messages: 39.2% reduction (713 → 434 tokens)
25 messages: 56.8% reduction (1017 → 439 tokens)
50 messages: 75.2% reduction (1762 → 436 tokens)
Context Maintenance:
Recipe is always preserved
Recent questions and answers are kept
System prompt is optimized based on query type
Performance Improvements:
Context retrieval time: ~0.001s
Consistent context size (6 messages) regardless of conversation length
Maintains all necessary context while significantly reducing tokens
The optimizations are now ready for production. Here's what users will experience:
Faster Responses: Due to reduced token count, API calls will be processed faster
Lower Costs: Significant reduction in token usage (up to 75% for longer conversations)
Maintained Quality:
Recipe details are always available
Recent context is preserved
Relevant Q&As are kept